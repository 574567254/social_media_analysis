{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35915b5e",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f2fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edce36d",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Find predictors of influence\n",
    "### Try different machine learning algorithms to choose the one that yields the highest accuracy score\n",
    "\n",
    "#### Data set description:\n",
    "Each observation describes two individuals, A and B. There are 11 variables for each person based on Twitter activity, e.g., number of followers, retweets, network characteristics, etc. Each observation shows whether A > B (Choice = “1”) or B > A (Choice = “0”).\n",
    "\n",
    "Perhaps a transformation of (A / B) or (A – B) variables will be better than using A \n",
    "and B variables separately. This may also be easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd89441",
   "metadata": {},
   "source": [
    "### 1. classification model with no column manipulation (i.e. no column interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72228c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2802\n",
       "0    2698\n",
       "Name: Choice, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Choice']\n",
    "X = df.drop(columns = 'Choice')\n",
    "y.value_counts() #it is balanced, we don't need to do anything on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "586ce973",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bcd5f",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15de1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso\n",
    "lasso = Lasso(alpha = 0.01)\n",
    "model_lasso = lasso.fit(X_std, y)\n",
    "model_lasso.coef_\n",
    "# store into dataframe\n",
    "lasso_df = pd.DataFrame(list(zip(X.columns, model_lasso.coef_)), columns = ['predictor','coefficient'])\n",
    "# convert to boolean, working as index for calling\n",
    "lasso_choose = []\n",
    "for i in lasso_df.index:\n",
    "    if lasso_df[\"coefficient\"][i] != 0:\n",
    "        lasso_choose.append(True)\n",
    "    else:\n",
    "        lasso_choose.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8a0131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random Forest\n",
    "randomforest = RandomForestClassifier(random_state = 42)\n",
    "model_rf = randomforest.fit(X, y)\n",
    "model_rf.feature_importances_ # the higher the score, the more important it is\n",
    "\n",
    "# store into dataframe\n",
    "rf_df = pd.DataFrame(list(zip(X.columns, model_rf.feature_importances_)), columns = ['predictor','feature importance'])\n",
    "# select those who pass the threshold, the common threshold is 0.05\n",
    "tf_list = []\n",
    "for i in rf_df.index:\n",
    "    if rf_df[\"feature importance\"][i] >= 0.05:\n",
    "        tf_list.append(True)\n",
    "    else:\n",
    "        tf_list.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2604774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting\n",
    "gbt = GradientBoostingClassifier()\n",
    "model_gbt = gbt.fit(X,y)\n",
    "model_gbt.feature_importances_\n",
    "threshold = 0.05\n",
    "\n",
    "# store into dataframe\n",
    "gbt_df = pd.DataFrame(list(zip(X.columns, model_gbt.feature_importances_)), columns = ['predictor','feature importance'])\n",
    "# select those who pass the threshold, the common threshold is 0.05\n",
    "gbt_list = []\n",
    "for i in gbt_df.index:\n",
    "    if gbt_df[\"feature importance\"][i] >= 0.05:\n",
    "        gbt_list.append(True)\n",
    "    else:\n",
    "        gbt_list.append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2156e6",
   "metadata": {},
   "source": [
    "### build classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########build classification models###############\n",
    "accuracy_list = []\n",
    "#####using lasso selected features#########\n",
    "_lasso = X.iloc[:, lasso_choose]\n",
    "_lasso_std = scaler.fit_transform(_lasso)\n",
    "#logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(_lasso_std, y, test_size = 0.2, random_state = 5)\n",
    "lr = LogisticRegression(max_iter = 10000)\n",
    "model_lr_lasso_selected = lr.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model_lr_lasso_selected.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Model (Lasso):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "acc_lr_lasso = ('lr_lasso', acc)\n",
    "accuracy_list.append(acc_lr_lasso)\n",
    "\n",
    "\n",
    "#xgb\n",
    "X_train, X_test, y_train, y_test = train_test_split(_lasso, y, test_size = 0.2, random_state = 5)\n",
    "xgb = XGBClassifier()\n",
    "model_xgb_lasso_selected = xgb.fit(X_train, y_train)\n",
    "y_test_pred = model_xgb_lasso_selected.predict(X_test)\n",
    "\n",
    "print(\"XGB (Lasso):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "acc_xgb_lasso = ('xgb_lasso', acc)\n",
    "accuracy_list.append(acc_xgb_lasso)\n",
    "\n",
    "\n",
    "#####using random forest selected features#########\n",
    "_rf = X.iloc[:, tf_list]\n",
    "_rf_std = scaler.fit_transform(_rf)\n",
    "#logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(_rf_std, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "model_lr_rf_selected = lr.fit(X_train, y_train)\n",
    "y_test_pred = model_lr_rf_selected.predict(X_test)\n",
    "print(\"Logistic Regression Model (random forest):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "acc_lr_rf = ('lr_rf', acc)\n",
    "accuracy_list.append(acc_lr_rf)\n",
    "\n",
    "#xgb\n",
    "X_train, X_test, y_train, y_test = train_test_split(_rf, y, test_size = 0.2, random_state = 5)\n",
    "xgb = XGBClassifier()\n",
    "model_xgb_rf_selected = xgb.fit(X_train, y_train)\n",
    "y_test_pred = model_xgb_rf_selected.predict(X_test)\n",
    "print(\"XGB (random forest):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "acc_xgb_rf = ('xgb_rf', acc)\n",
    "accuracy_list.append(acc_xgb_rf)\n",
    "\n",
    "#####using GBT selected features#########\n",
    "_gbt = X.iloc[:, gbt_list]\n",
    "_gbt_std = scaler.fit_transform(_gbt)\n",
    "#logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(_gbt_std, y, test_size = 0.2, random_state = 5)\n",
    "model_lr_gbt_selected = lr.fit(X_train, y_train)\n",
    "y_test_pred = model_lr_gbt_selected.predict(X_test)\n",
    "print(\"Logistic Regression Model (GBT):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "acc_lr_gbt = ('lr_gbt', acc)\n",
    "accuracy_list.append(acc_lr_gbt)\n",
    "\n",
    "#XGB\n",
    "X_train, X_test, y_train, y_test = train_test_split(_gbt, y, test_size = 0.2,random_state = 5)\n",
    "xgb = XGBClassifier()\n",
    "model_xgb_gbt_selected = xgb.fit(X_train, y_train)\n",
    "y_test_pred = model_xgb_gbt_selected.predict(X_test)\n",
    "print(\"XGB (GBT):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "acc_xgb_gbt = ('xgb_gbt', acc)\n",
    "accuracy_list.append(acc_xgb_gbt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260263c5",
   "metadata": {},
   "source": [
    "### 2. classification model with columns A-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bd9ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "Adf = df.iloc[:, 1:12].values\n",
    "Bdf = df.iloc[:, 12:].values\n",
    "new_df = Adf - Bdf\n",
    "new_df = pd.DataFrame({'A-B_follower_count': new_df[:, 0], 'A-B_following_count': new_df[:, 1],\n",
    "                       'A-B_listed_count': new_df[:,2], 'A-B_mentions_received': new_df[:,3],\n",
    "                       'A-B_retweets_received': new_df[:,4], 'A-B_mentions_sent': new_df[:,5],\n",
    "                       'A-B_retweets_sent': new_df[:,6], 'A-B_posts': new_df[:,7],\n",
    "                       'A-B_network_feature_1': new_df[:,8], 'A-B_network_feature_2': new_df[:,9],\n",
    "                       'A-B_network_feature_3': new_df[:,10]})\n",
    "new_df['Choice'] = df['Choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f458c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df['Choice']\n",
    "X = new_df.drop(columns = 'Choice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c617c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9e16f",
   "metadata": {},
   "source": [
    "### Classification model with no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee4c26c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:\n",
      "Classification Accuracy: 0.79\n",
      "Precision 0.7787307032590052\n",
      "Recall: 0.8165467625899281\n",
      "logistic regression:\n",
      "Classification Accuracy: 0.7572727272727273\n",
      "Precision 0.7584973166368515\n",
      "Recall: 0.762589928057554\n",
      "GBT:\n",
      "Classification Accuracy: 0.8\n",
      "Precision 0.788659793814433\n",
      "Recall: 0.8255395683453237\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "##Random forest\n",
    "randomforest = RandomForestClassifier()\n",
    "model = randomforest.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Random forest:\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "##logistic regression\n",
    "lr1 = LogisticRegression(max_iter=1000)\n",
    "model2 = lr1.fit(X_train,y_train)\n",
    "y_test_pred = model2.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"logistic regression:\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "#GBT\n",
    "gbt = GradientBoostingClassifier(random_state=5,min_samples_split = 8, n_estimators = 100)\n",
    "model3 = gbt.fit(X_train,y_train)\n",
    "y_test_pred = model3.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"GBT:\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24735ffa",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76067c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso\n",
    "lasso = Lasso(alpha = 0.01)\n",
    "model_lasso = lasso.fit(X_std, y)\n",
    "model_lasso.coef_\n",
    "# store into dataframe\n",
    "lasso_df = pd.DataFrame(list(zip(X.columns, model_lasso.coef_)), columns = ['predictor','coefficient'])\n",
    "# convert to boolean, working as index for calling\n",
    "lasso_choose = []\n",
    "for i in lasso_df.index:\n",
    "    if lasso_df[\"coefficient\"][i] != 0:\n",
    "        lasso_choose.append(True)\n",
    "    else:\n",
    "        lasso_choose.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4f30fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random Forest\n",
    "randomforest = RandomForestClassifier(random_state = 42)\n",
    "model_rf = randomforest.fit(X, y)\n",
    "model_rf.feature_importances_ # the higher the score, the more important it is\n",
    "\n",
    "# store into dataframe\n",
    "rf_df = pd.DataFrame(list(zip(X.columns, model_rf.feature_importances_)), columns = ['predictor','feature importance'])\n",
    "# select those who pass the threshold, the common threshold is 0.05\n",
    "tf_list = []\n",
    "for i in rf_df.index:\n",
    "    if rf_df[\"feature importance\"][i] >= 0.05:\n",
    "        tf_list.append(True)\n",
    "    else:\n",
    "        tf_list.append(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a215c2",
   "metadata": {},
   "source": [
    "### build classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf59e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model (Lasso selected):\n",
      "Classification Accuracy: 0.7445454545454545\n",
      "Precision 0.7342419080068143\n",
      "Recall: 0.7751798561151079\n",
      "Random Forest Model (Lasso selected):\n",
      "Classification Accuracy: 0.7836363636363637\n",
      "Precision 0.7750865051903114\n",
      "Recall: 0.8057553956834532\n"
     ]
    }
   ],
   "source": [
    "########build classification models###############\n",
    "accuracy_list = []\n",
    "#####using lasso selected features#########\n",
    "_lasso = X.iloc[:, lasso_choose]\n",
    "_lasso_std = scaler.fit_transform(_lasso)\n",
    "#logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(_lasso_std, y, test_size = 0.2, random_state = 5)\n",
    "lr = LogisticRegression(max_iter = 10000)\n",
    "model_lr_lasso_selected = lr.fit(X_train, y_train)\n",
    "y_test_pred = model_lr_lasso_selected.predict(X_test)\n",
    "print(\"Logistic Regression Model (Lasso selected):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "acc_lr_lasso = ('lr_lasso', acc)\n",
    "accuracy_list.append(acc_lr_lasso)\n",
    "\n",
    "\n",
    "##Random forest\n",
    "randomforest = RandomForestClassifier()\n",
    "model2 = randomforest.fit(X_train, y_train)\n",
    "y_test_pred = model2.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "print(\"Random Forest Model (Lasso selected):\")\n",
    "acc2 = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc2)\n",
    "pre2 = metrics.precision_score(y_test, y_test_pred)\n",
    "recall2 = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Precision\", pre2)\n",
    "print(\"Recall:\", recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3652590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model (random forest selected):\n",
      "Classification Accuracy: 0.74\n",
      "Precision 0.7265536723163842\n",
      "Recall: 0.7746987951807229\n",
      "Random Forest Model (random forest selected):\n",
      "Classification Accuracy: 0.7745454545454545\n",
      "Precision 0.7700471698113207\n",
      "Recall: 0.7867469879518072\n"
     ]
    }
   ],
   "source": [
    "#####using random forest selected features#########\n",
    "_rf = X.iloc[:, tf_list]\n",
    "_rf_std = scaler.fit_transform(_rf)\n",
    "#logistic regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(_rf_std, y, test_size = 0.3, random_state = 42)\n",
    "model_lr_rf_selected = lr.fit(X_train, y_train)\n",
    "y_test_pred = model_lr_rf_selected.predict(X_test)\n",
    "print(\"Logistic Regression Model (random forest selected):\")\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "pre = metrics.precision_score(y_test, y_test_pred)\n",
    "recall = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc)\n",
    "print(\"Precision\", pre)\n",
    "print(\"Recall:\", recall)\n",
    "acc_lr_rf = ('lr_rf', acc)\n",
    "accuracy_list.append(acc_lr_rf)\n",
    "\n",
    "##Random forest\n",
    "randomforest = RandomForestClassifier()\n",
    "model2 = randomforest.fit(X_train, y_train)\n",
    "y_test_pred = model2.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "print(\"Random Forest Model (random forest selected):\")\n",
    "acc2 = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Classification Accuracy:\", acc2)\n",
    "pre2 = metrics.precision_score(y_test, y_test_pred)\n",
    "recall2 = metrics.recall_score(y_test, y_test_pred)\n",
    "print(\"Precision\", pre2)\n",
    "print(\"Recall:\", recall2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7624103",
   "metadata": {},
   "source": [
    "### 3. classification model with columns A/B¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b0dce708",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,0]\n",
    "df_a = df.iloc[:,1:12].values\n",
    "df_b = df.iloc[:,12:].values\n",
    "\n",
    "## change zero values\n",
    "for i in range(len(df_a)):\n",
    "    for j in range(len(df_a[i])):\n",
    "        if df_a[i][j] == 0 :\n",
    "            df_a[i][j] = 0.000001\n",
    "        if df_b[i][j] == 0 :\n",
    "            df_b[i][j] = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a3c5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## division\n",
    "X = df_a/df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8b8834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature =[\"follower\",\"following\",\"listed\",\"mentions_received\",\"retweets_received\",\"mentions_sent\",\"retweet_received\",\n",
    "          \"posts\",\"network_feature_1\",\"network_feature_2\",\"network_feature_3\"]\n",
    "X = pd.DataFrame(X,columns = feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c959a",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf6708bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find collinear terms\n",
    "\n",
    "df_all = pd.concat([X,y], axis=1)\n",
    "\n",
    "correlation = df_all.corr()\n",
    "correlation_var = []\n",
    "for j in range(0,len(correlation)-1):\n",
    "    i=j+1\n",
    "    while i < len(correlation):\n",
    "        if abs(correlation.iloc[i,j]) >= 0.7:\n",
    "            correlation_var.append([correlation.index[i],correlation.columns[j],correlation.iloc[i,j]])\n",
    "        i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ecaa6cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['retweets_received', 'mentions_received', 0.7863380042405462],\n",
       " ['network_feature_1', 'mentions_received', 0.8917248110430861]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2bfc9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = [\"mentions_received\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb0891",
   "metadata": {},
   "source": [
    "### RF feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "886296cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to perform feature selection on predictors\n",
    "## Random Forest\n",
    "randomforest = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "model = randomforest.fit(X,y)\n",
    "model.feature_importances_\n",
    "feature_result = pd.DataFrame(list(zip(X.columns,model.feature_importances_)), columns = ['predictor','feature_importance'])\n",
    "\n",
    "## set the threshold of random forest feature selection result to be 0.01\n",
    "## obtained the list of predictorss\n",
    "var_list = []\n",
    "for i in range(len(feature_result.predictor)):\n",
    "    if feature_result.loc[i,'feature_importance'] >= 0.1:\n",
    "        var_list.append(feature_result.predictor.loc[i])\n",
    "\n",
    "X_rf = X[var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c181df35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follower</th>\n",
       "      <th>listed</th>\n",
       "      <th>retweets_received</th>\n",
       "      <th>network_feature_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.025227</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.549921</td>\n",
       "      <td>0.141615</td>\n",
       "      <td>2.884551</td>\n",
       "      <td>2.263804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.018222</td>\n",
       "      <td>0.490291</td>\n",
       "      <td>26.966469</td>\n",
       "      <td>31.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.003405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.035081</td>\n",
       "      <td>14.591160</td>\n",
       "      <td>10.330091</td>\n",
       "      <td>6.482353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>0.051921</td>\n",
       "      <td>0.089546</td>\n",
       "      <td>0.056418</td>\n",
       "      <td>0.138033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>0.141058</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.328364</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>2.036669</td>\n",
       "      <td>4.127072</td>\n",
       "      <td>6.232288</td>\n",
       "      <td>2.376471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>0.822042</td>\n",
       "      <td>0.024784</td>\n",
       "      <td>10.811390</td>\n",
       "      <td>3.739943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      follower     listed  retweets_received  network_feature_1\n",
       "0     0.006616   0.001776           0.025227           0.030303\n",
       "1     0.549921   0.141615           2.884551           2.263804\n",
       "2     2.018222   0.490291          26.966469          31.666667\n",
       "3     0.001022   0.007194           0.000711           0.003405\n",
       "4     6.035081  14.591160          10.330091           6.482353\n",
       "...        ...        ...                ...                ...\n",
       "5495  0.051921   0.089546           0.056418           0.138033\n",
       "5496  0.141058   0.625000           0.328364           5.000000\n",
       "5497  2.036669   4.127072           6.232288           2.376471\n",
       "5498  0.822042   0.024784          10.811390           3.739943\n",
       "5499  0.001246   0.000470           0.004337           0.006250\n",
       "\n",
       "[5500 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc1d2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_rf,y,test_size=0.2,random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ac492",
   "metadata": {},
   "source": [
    "### build classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08ac4529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5227272727272727"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000) \n",
    "model1 = lr.fit(X_train,y_train)\n",
    "y_test_pred = model1.predict(X_test)\n",
    "ls_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "ls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "10065962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745454545454545"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RANDOM FOREST\n",
    "\n",
    "randomforest = RandomForestClassifier(random_state=5)\n",
    "\n",
    "model2 = randomforest.fit(X_train,y_train) \n",
    "y_test_pred = model2.predict(X_test)\n",
    "rf_score = metrics.accuracy_score(y_test,y_test_pred)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "709d36cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 0.7575000000000001\n",
      "4 : 0.7563636363636363\n",
      "6 : 0.7595454545454545\n",
      "8 : 0.7563636363636362\n",
      "10 : 0.7545454545454545\n",
      "12 : 0.7549999999999999\n",
      "14 : 0.7561363636363637\n",
      "16 : 0.7565909090909091\n",
      "18 : 0.7543181818181818\n"
     ]
    }
   ],
   "source": [
    "## GRADIENT BOOST\n",
    "\n",
    "## uncomment the following lines to see how to find the optimal min_samples_split value\n",
    "for i in range(1,10):\n",
    "    model = GradientBoostingClassifier(random_state=0,min_samples_split = i*2, n_estimators = 100)\n",
    "    scores = cross_val_score(estimator = model, X=X_train, y=y_train, cv=5)\n",
    "    print(i*2,':',np.average(scores))\n",
    "## i =8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c75047a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972727272727272"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier(random_state=0,min_samples_split = 6, n_estimators = 100)\n",
    "model3 = gbt.fit(X_train,y_train)\n",
    "y_test_pred = model3.predict(X_test)\n",
    "gbt_score = metrics.accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "gbt_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402d782",
   "metadata": {},
   "source": [
    "## choose the one that yields the highest accuracy score\n",
    "From the accuracy of all the models above, we have the highest accuracy in the GBT Model for paired columns by doing A-B, without further feature selection. And the accuracy of this model is 0.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dacc10",
   "metadata": {},
   "source": [
    "## Task: To find out the best predictor in this GBT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed6a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = new_df['Choice']\n",
    "X = new_df.drop(columns = 'Choice')\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "gbt = GradientBoostingClassifier(random_state=5,min_samples_split = 8, n_estimators = 100)\n",
    "model3 = gbt.fit(X_train,y_train)\n",
    "y_test_pred = model3.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e2ff6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "425aa12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "pyplot.bar(range(len(model3.feature_importances_)), model3.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cf140ead",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three best predictors in this model: A-B_listed_count , A-B_follower_count , A-B_network_feature_1 , A-B_retweets_received\n"
     ]
    }
   ],
   "source": [
    "important_features = X.columns.values.tolist()\n",
    "print('Three best predictors in this model:', important_features[2], ',', important_features[0],\n",
    "     ',', important_features[8], ',', important_features[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf9230",
   "metadata": {},
   "source": [
    "### Four best predictors in this model: \n",
    "A-B_listed_count , A-B_follower_count , A-B_network_feature_1 and A-B_retweets_received. \n",
    "\n",
    "This is kind of suprising because we thought the difference in the number of mentions received should also be of top importance, but it's not in the most important four predictors.\n",
    "\n",
    "This model can be used to predict the power of influence of user on social media (eg.  Twitter). Business can use the difference in the number of listed, number of followers, degrees centrality and the number of retweets received to determine which user is more influential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "078cffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3879603043778103 , 0.1766648317226786 , 0.12718548362682655 , 0.0962322414260105\n"
     ]
    }
   ],
   "source": [
    "##print the feature importance of the top four importance predictors\n",
    "print(model3.feature_importances_[2], ',', model3.feature_importances_[0],\n",
    "     ',', model3.feature_importances_[8], ',', model3.feature_importances_[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3b9aa",
   "metadata": {},
   "source": [
    "## Task: Financial Value Calculation\n",
    "\n",
    "#### Assumption:\n",
    "A retailer wants influencers to tweet its promotion for a product. If a non-influencer \n",
    "tweets, there is no benefit to the retailer. If an influencer tweets once, there is a 0.02%\n",
    "chance that his/her followers will buy one unit of a product. Assume the retailer has a \n",
    "profit margin of 10 per unit, and that one customer can buy only one unit. If an \n",
    "influencer tweets twice, the overall buying probability will be 0.03%. Without analytics, \n",
    "the retailer offers 5 to each person (A and B) to tweet once. With analytics, the retailer \n",
    "offers 10 to those identified as influencers by the model to send two tweets each. If \n",
    "the model classifies an individual as a non-influencer, s/he is not selected/paid by the \n",
    "retailer to tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d39ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "df=pd.read_csv('train.csv')\n",
    "Adf = df.iloc[:, 1:12].values\n",
    "Bdf = df.iloc[:, 12:].values\n",
    "new_df = Adf - Bdf\n",
    "new_df = pd.DataFrame({'A-B_follower_count': new_df[:, 0], 'A-B_following_count': new_df[:, 1],\n",
    "                       'A-B_listed_count': new_df[:,2], 'A-B_mentions_received': new_df[:,3],\n",
    "                       'A-B_retweets_received': new_df[:,4], 'A-B_mentions_sent': new_df[:,5],\n",
    "                       'A-B_retweets_sent': new_df[:,6], 'A-B_posts': new_df[:,7],\n",
    "                       'A-B_netwbork_feature_1': new_df[:,8], 'A-B_network_feature_2': new_df[:,9],\n",
    "                       'A-B_network_feature_3': new_df[:,10]})\n",
    "new_df['Choice'] = df['Choice']\n",
    "y = new_df['Choice']\n",
    "X = new_df.drop(columns = 'Choice')\n",
    "gbt = GradientBoostingClassifier(random_state=5,min_samples_split = 8, n_estimators = 100)\n",
    "model3 = gbt.fit(X_train,y_train)\n",
    "y_test_pred = model3.predict(X_test)\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67615418",
   "metadata": {},
   "source": [
    "### To find out  the boost in expected net profit from using our analytic model (versus not using analytics)\n",
    "\n",
    "### To find out the boost in net profit from using a perfect analytic model (versus not using analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7802e8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boost in expected net profit from using an analytic model is 10713424.716000035\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df = df[['A_follower_count','B_follower_count']]\n",
    "df['influencer_pre'] = model3.predict(X)\n",
    "df['influencer_pre'] = np.where(df['influencer_pre']==1, 'A', 'B')\n",
    "EXRevenue_model = 0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,2] == 'B':\n",
    "        EXRevenue_model += df.iloc[i, 1]*(0.03/100)*10\n",
    "    if df.iloc[i,2] == 'A':\n",
    "        EXRevenue_model += df.iloc[i, 0]*(0.03/100)*10\n",
    "EXprofit_model = EXRevenue_model - len(df)*10\n",
    "EXprofit_model\n",
    "\n",
    "EXRevenue_nomodel = 0\n",
    "for i in range(len(df)):\n",
    "    EXRevenue_nomodel += 0.5*df.iloc[i, 1]*(0.02/100)*10 + 0.5*df.iloc[i, 0]*(0.02/100)*10\n",
    "EXprofit_nomodel = EXRevenue_nomodel - len(df)*10\n",
    "\n",
    "EXprofit_nomodel\n",
    "\n",
    "print('boost in expected net profit from using an analytic model is', EXprofit_model-EXprofit_nomodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6117c611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4696984322244175"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(EXprofit_model-EXprofit_nomodel)/EXprofit_nomodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e442d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boost in net profit from using a perfect analytic model is 8785166.318999972\n"
     ]
    }
   ],
   "source": [
    "##boost in net profit from using a perfect analytic model\n",
    "import numpy as np\n",
    "df = pd.read_csv('train.csv')\n",
    "df['influencer'] = np.where(df['Choice']==1, 'A', 'B')\n",
    "df = df[['influencer','A_follower_count','B_follower_count']]\n",
    "df\n",
    "\n",
    "Revenue_model = 0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,0] == 'B':\n",
    "        Revenue_model += df.iloc[i, 2]*(0.03/100)*10\n",
    "    if df.iloc[i,0] == 'A':\n",
    "        Revenue_model += df.iloc[i, 1]*(0.03/100)*10\n",
    "profit_model = Revenue_model - len(df)*10\n",
    "profit_model\n",
    "\n",
    "Revenue_nomodel = 0\n",
    "for i in range(len(df)):\n",
    "    Revenue_nomodel += 0.5*df.iloc[i, 1]*(0.02/100)*10 + 0.5*df.iloc[i, 2]*(0.02/100)*10\n",
    "profit_nomodel = Revenue_nomodel - len(df)*10\n",
    "\n",
    "profit_nomodel\n",
    "\n",
    "print('boost in net profit from using a perfect analytic model is', profit_model-profit_nomodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7590a258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.205174396435734"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(profit_model-profit_nomodel)/profit_nomodel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf29a90",
   "metadata": {},
   "source": [
    "### Financial value calculation results:\n",
    "boost in expected net profit from using an analytic model is 10713424.716000035\n",
    "\n",
    "boost in net profit from using a perfect analytic model is 8785166.318999972\n",
    "\n",
    "The boost in the expected net profit is higher compared with the net profit from using a perfect analytic model, this might because the prediction model tends to rely more on the number of followers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315d08a",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "## Task: Find influencers from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa866078",
   "metadata": {},
   "source": [
    "Collect about 5,000 tweets about Tesla. \n",
    "Write a script that parses through the tweets and does the following for each tweet:\n",
    "\n",
    "Any retweet, mention or reply should result in an edge from the person retweeting to \n",
    "the person retweeted, mentioned or replied to. Save it into a 3-column csv file.\n",
    "\n",
    "Use NodeXL to draw networks\n",
    "\n",
    "Calculate the degree, betweenness and closeness of each node in the above network.\n",
    "\n",
    "Using the results from Part I, create a list of top 100 influencers from the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011af571",
   "metadata": {},
   "source": [
    "### Webscriping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1458f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code shows how to scrape twitter by using the snscrape python API\n",
    "# Please make sure the snscrape has been installed in the local environment\n",
    "# The snscape package can be installed by: pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "# The Python version has to be greater than 3.8\n",
    "# An alternative Python method is to to execute CLI commands in Python. \n",
    "# Please check this link for more details: https://colab.research.google.com/drive/1ugr1biGxV9C2OwzS3HEh3KM0z2Xg44jb?usp=sharing\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "key_word = \"Tesla\"  # Declare the key word used to search tweets\n",
    "#user_name = \"@elonmusk\"   # Declare a user name used to search tweets\n",
    "from_date = \"2021-01-01\" # Declare a start date\n",
    "end_date = '2022-02-01'  # Declare a end date\n",
    "count = 5000             # The maximum number of tweets\n",
    "tweets_list_keyword = [] # A list used to store the returned results for keyword search\n",
    "tweets_list_user = []    # A list used to store the retuned results for user search\n",
    "\n",
    "\n",
    "#### Scraping tweets from a text search query ####\n",
    "command_keyword = key_word+' since:'+from_date+' until:'+end_date # Define a string command for Scraper Api\n",
    "print(\"Scraping data for keyword:\",key_word)\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(command_keyword).get_items()):\n",
    "    tweets_list_keyword.append([tweet.id, tweet.content, tweet.user.username, tweet.user.followersCount,tweet.user.listedCount,tweet.retweetedTweet]) # Append returned results to list\n",
    "    if i>count:\n",
    "        break;\n",
    "#Create a dataframe from the tweets list above \n",
    "tweets_df_keyword = pd.DataFrame(tweets_list_keyword, columns=['Tweet Id', 'Text', 'Username', 'followers','listedcount','retweeted'])\n",
    "tweets_df_keyword.to_csv(\"tweets_keywords.csv\",index=False) # Export to a csv file\n",
    "print(\"Scraped data have been exported to the csv file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45275d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>followers</th>\n",
       "      <th>listedcount</th>\n",
       "      <th>retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488301057650438144</td>\n",
       "      <td>oh yeah tesla well what about a car that just ...</td>\n",
       "      <td>christrebecca</td>\n",
       "      <td>805</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488301049895079938</td>\n",
       "      <td>@parzr1 @fungineer43 @hikingskiing @elonmusk I...</td>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1488301028592214018</td>\n",
       "      <td>+$19,657 #QQQ #Tesla #spy https://t.co/q8Qm017Ik7</td>\n",
       "      <td>Picstocktrading</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1488301021382205445</td>\n",
       "      <td>nuevo - Tesla añadirá un micrófono para karaok...</td>\n",
       "      <td>bettyromerito</td>\n",
       "      <td>1644</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1488300978201935872</td>\n",
       "      <td>@elwalvador I like coke.  Have my doubts about...</td>\n",
       "      <td>TheDonSean</td>\n",
       "      <td>379</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet Id                                               Text  \\\n",
       "0  1488301057650438144  oh yeah tesla well what about a car that just ...   \n",
       "1  1488301049895079938  @parzr1 @fungineer43 @hikingskiing @elonmusk I...   \n",
       "2  1488301028592214018  +$19,657 #QQQ #Tesla #spy https://t.co/q8Qm017Ik7   \n",
       "3  1488301021382205445  nuevo - Tesla añadirá un micrófono para karaok...   \n",
       "4  1488300978201935872  @elwalvador I like coke.  Have my doubts about...   \n",
       "\n",
       "          Username  followers  listedcount  retweeted  \n",
       "0    christrebecca        805           13          0  \n",
       "1       CarlisleDB        193            2          0  \n",
       "2  Picstocktrading         24            0          0  \n",
       "3    bettyromerito       1644          117          0  \n",
       "4       TheDonSean        379           31          0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = pd.read_csv(\"tweets_keywords.csv\")\n",
    "tweet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d6e8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text  = tweet.Text.values\n",
    "tweet_text = tweet_text.tolist()\n",
    "user = tweet.Username.values\n",
    "user = user.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7534f611",
   "metadata": {},
   "source": [
    "## Task: Detect languages\n",
    "\n",
    "Non English tweet will mess up the user name format. Thus, we want to remove the non-english tweets.\n",
    "\n",
    "Remove odd tweet. The tweet below cannot apply language detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39a4c5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@kentcdodds @Tesla ❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️❤️'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_tweet = tweet_text[1814]\n",
    "tweet_text.pop(1814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f82a16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FiveTweetTSLA'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_tweet_user = user[1814]\n",
    "user.pop(1814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ac292ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(tweet_text, user)),columns = [\"tweet\",'user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c280d",
   "metadata": {},
   "source": [
    "### Detect languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95bcf4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "language = []\n",
    "for i in range(len(df.tweet)):\n",
    "    lan = detect(df.tweet.iloc[i])\n",
    "    language.append(lan)\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2be19187",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en = []\n",
    "for i in range(len(language)):\n",
    "    if language[i] != 'en':\n",
    "        non_en.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac1f1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(non_en) ## drop non-english tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c95ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text = df.tweet.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca5b3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "non_tweet_users = []\n",
    "for t in en_text:\n",
    "    \n",
    "    non_tweet_users.append(re.findall(r'[@]\\S*', t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edd2379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_users = df.user.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c846c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(non_tweet_users)):\n",
    "    if len(non_tweet_users[i]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        for j in range(len(non_tweet_users[i])):\n",
    "            char = list(non_tweet_users[i][j])\n",
    "            char.remove('@')\n",
    "            name = ''.join(char)\n",
    "            non_tweet_users[i][j] = name   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1284d",
   "metadata": {},
   "source": [
    "### Detect tweet type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f3112dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = []\n",
    "for i in non_tweet_users:\n",
    "    if len(i) == 0:\n",
    "        typ.append('t')\n",
    "    else:\n",
    "        typ.append('nt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c841cb0",
   "metadata": {},
   "source": [
    "### Final 3-column network csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5c018af",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns = ['column1','column2','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfa11ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(typ)):\n",
    "    if typ[i] == 't':\n",
    "        output = output.append(pd.Series([tweet_users[i],tweet_users[i],typ[i]], index=['column1','column2','type']), ignore_index=True)\n",
    "    if typ[i] != 't':\n",
    "        for j in range(len(non_tweet_users[i])):\n",
    "            output = output.append(pd.Series([non_tweet_users[i][j],tweet_users[i],typ[i]], index=['column1','column2','type']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cf40bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christrebecca</td>\n",
       "      <td>christrebecca</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parzr1</td>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fungineer43</td>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hikingskiing</td>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>Kristennetten</td>\n",
       "      <td>ArchieMcMurdo</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>live_munro</td>\n",
       "      <td>ArchieMcMurdo</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159</th>\n",
       "      <td>BillyM2k</td>\n",
       "      <td>ArchieMcMurdo</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>Grimezsz</td>\n",
       "      <td>ArchieMcMurdo</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>TSLAFanatic</td>\n",
       "      <td>TSLAFanatic</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10162 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             column1        column2 type\n",
       "0      christrebecca  christrebecca    t\n",
       "1             parzr1     CarlisleDB   nt\n",
       "2        fungineer43     CarlisleDB   nt\n",
       "3       hikingskiing     CarlisleDB   nt\n",
       "4           elonmusk     CarlisleDB   nt\n",
       "...              ...            ...  ...\n",
       "10157  Kristennetten  ArchieMcMurdo   nt\n",
       "10158     live_munro  ArchieMcMurdo   nt\n",
       "10159       BillyM2k  ArchieMcMurdo   nt\n",
       "10160       Grimezsz  ArchieMcMurdo   nt\n",
       "10161    TSLAFanatic    TSLAFanatic    t\n",
       "\n",
       "[10162 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f828873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = []\n",
    "for i in range(len(output.column1)):\n",
    "    if output.column1[i] == '':\n",
    "        ind.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4529a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.drop(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6be1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('part2.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6ca1c",
   "metadata": {},
   "source": [
    "## Task: draw networks\n",
    "### Import Metrics produced from NodeXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cdf6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_excel(\"part2_with_metrics.xlsx\",header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e712864",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop_duplicates(subset=None, keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea9d91",
   "metadata": {},
   "source": [
    "### Calculated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c01de58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = features.join(tweet, lsuffix='Vertex', rsuffix='Username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "646d7ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vertex</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Betweenness Centrality</th>\n",
       "      <th>Closeness Centrality</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>followers</th>\n",
       "      <th>listedcount</th>\n",
       "      <th>retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLAFanatic</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1488301057650438144</td>\n",
       "      <td>oh yeah tesla well what about a car that just ...</td>\n",
       "      <td>christrebecca</td>\n",
       "      <td>805</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gee_C_NSEW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>1488301049895079938</td>\n",
       "      <td>@parzr1 @fungineer43 @hikingskiing @elonmusk I...</td>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArchieMcMurdo</td>\n",
       "      <td>15</td>\n",
       "      <td>4569.119965</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1488301028592214018</td>\n",
       "      <td>+$19,657 #QQQ #Tesla #spy https://t.co/q8Qm017Ik7</td>\n",
       "      <td>Picstocktrading</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OmfStucky</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1488301021382205445</td>\n",
       "      <td>nuevo - Tesla añadirá un micrófono para karaok...</td>\n",
       "      <td>bettyromerito</td>\n",
       "      <td>1644</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POTUS</td>\n",
       "      <td>210</td>\n",
       "      <td>212305.994285</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1488300978201935872</td>\n",
       "      <td>@elwalvador I like coke.  Have my doubts about...</td>\n",
       "      <td>TheDonSean</td>\n",
       "      <td>379</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>fungineer43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1488233083858219008</td>\n",
       "      <td>quem são Michelangelo, Isaac newton, Beethoven...</td>\n",
       "      <td>Onidsinuca</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>parzr1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1488233036751716359</td>\n",
       "      <td>Tesla opened up 15 superchargers in Norway for...</td>\n",
       "      <td>MichalTeslaEu</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>christrebecca</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1488233029722116099</td>\n",
       "      <td>Mega promotion from OKX, play and win Tesla\\n\\...</td>\n",
       "      <td>PawelWz</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>column1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1488233024789659652</td>\n",
       "      <td>Introducing Plaid Track Mode\\nhttps://t.co/twa...</td>\n",
       "      <td>QS2Point</td>\n",
       "      <td>1626</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>column2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1488233023225184267</td>\n",
       "      <td>Tesla climbs nearly 10% on Monday after Credit...</td>\n",
       "      <td>Newsroomoffical</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4714 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Vertex  Degree  Betweenness Centrality  Closeness Centrality  \\\n",
       "0       TSLAFanatic       2                0.000000              0.000000   \n",
       "1        Gee_C_NSEW       1                0.000000              0.000099   \n",
       "2     ArchieMcMurdo      15             4569.119965              0.000133   \n",
       "3         OmfStucky       2                0.000000              0.000000   \n",
       "4             POTUS     210           212305.994285              0.000117   \n",
       "...             ...     ...                     ...                   ...   \n",
       "4709    fungineer43       1                0.000000              0.000088   \n",
       "4710         parzr1       1                0.000000              0.000088   \n",
       "4711  christrebecca       2                0.000000              0.000000   \n",
       "4712        column1       1                0.000000              1.000000   \n",
       "4713        column2       1                0.000000              1.000000   \n",
       "\n",
       "                 Tweet Id                                               Text  \\\n",
       "0     1488301057650438144  oh yeah tesla well what about a car that just ...   \n",
       "1     1488301049895079938  @parzr1 @fungineer43 @hikingskiing @elonmusk I...   \n",
       "2     1488301028592214018  +$19,657 #QQQ #Tesla #spy https://t.co/q8Qm017Ik7   \n",
       "3     1488301021382205445  nuevo - Tesla añadirá un micrófono para karaok...   \n",
       "4     1488300978201935872  @elwalvador I like coke.  Have my doubts about...   \n",
       "...                   ...                                                ...   \n",
       "4709  1488233083858219008  quem são Michelangelo, Isaac newton, Beethoven...   \n",
       "4710  1488233036751716359  Tesla opened up 15 superchargers in Norway for...   \n",
       "4711  1488233029722116099  Mega promotion from OKX, play and win Tesla\\n\\...   \n",
       "4712  1488233024789659652  Introducing Plaid Track Mode\\nhttps://t.co/twa...   \n",
       "4713  1488233023225184267  Tesla climbs nearly 10% on Monday after Credit...   \n",
       "\n",
       "             Username  followers  listedcount  retweeted  \n",
       "0       christrebecca        805           13          0  \n",
       "1          CarlisleDB        193            2          0  \n",
       "2     Picstocktrading         24            0          0  \n",
       "3       bettyromerito       1644          117          0  \n",
       "4          TheDonSean        379           31          0  \n",
       "...               ...        ...          ...        ...  \n",
       "4709       Onidsinuca        175            0          0  \n",
       "4710    MichalTeslaEu        146            1          0  \n",
       "4711          PawelWz         48            4          0  \n",
       "4712         QS2Point       1626          186          0  \n",
       "4713  Newsroomoffical         22            0          0  \n",
       "\n",
       "[4714 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29c3d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(list(zip(df_join.Username,df_join.followers,df_join.listedcount,df_join.retweeted,df_join.Degree)), columns =  [\"user\",\"followers\",\"listed\",\"retweeted\",\"degree\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c16d82",
   "metadata": {},
   "source": [
    "## Task: Using the results from Part I, create a list of top 100 influencers from the tweets.\n",
    "\n",
    "Choose the weights (it is subjective) such that bigger weights are given to factors that \n",
    "were more important (as judged by, for example, coefficients and p values in Part I).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11c397e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>followers</th>\n",
       "      <th>listed</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christrebecca</td>\n",
       "      <td>805</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CarlisleDB</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Picstocktrading</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bettyromerito</td>\n",
       "      <td>1644</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TheDonSean</td>\n",
       "      <td>379</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user  followers  listed  retweeted  degree\n",
       "0    christrebecca        805      13          0       2\n",
       "1       CarlisleDB        193       2          0       1\n",
       "2  Picstocktrading         24       0          0      15\n",
       "3    bettyromerito       1644     117          0       2\n",
       "4       TheDonSean        379      31          0     210"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b030b134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3677"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data.user.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e67e6",
   "metadata": {},
   "source": [
    "### Normalize the data before creating the overall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "810b9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.49\n",
    "w2 = 0.22\n",
    "w3 = 0.16\n",
    "w4 = 0.13\n",
    "\n",
    "score = w4*final_data.retweeted + w2*final_data.followers+w1*final_data.listed+w3*final_data.degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "936c3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "298bff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop_duplicates(subset=['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "069ff829",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = final_data.sort_values('score', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0d2a30",
   "metadata": {},
   "source": [
    "## Top 100 User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "579a3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user = top_100.user.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a321ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = pd.DataFrame(columns = ['column1','column2','type'])\n",
    "for i in range(len(output)):\n",
    "    if output.column1.iloc[i] in top_user:\n",
    "        top1 = top1.append(pd.Series([output.column1.iloc[i],output.column2.iloc[i],output.type.iloc[i]], index=['column1','column2','type']), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51d84ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top2 = pd.DataFrame(columns = ['column1','column2','type'])\n",
    "for i in range(len(top1)):\n",
    "    if output.column2.iloc[i] in top_user:\n",
    "        top2 = top2.append(pd.Series([top1.column1.iloc[i],top1.column2.iloc[i],top1.type.iloc[i]], index=['column1','column2','type']), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15de0053",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WholeMarsBlog</td>\n",
       "      <td>Trotter87528503</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Space_Dog_Phill</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>mrstego1</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EvaFoxU</td>\n",
       "      <td>1sammyson</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ray4tesla</td>\n",
       "      <td>TONE13817103</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>otacon122</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ray4tesla</td>\n",
       "      <td>ray4tesla</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GailAlfarATX</td>\n",
       "      <td>otacon122</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>Leonari13</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>elonmusk</td>\n",
       "      <td>thiseffinguy7</td>\n",
       "      <td>nt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          column1          column2 type\n",
       "0   WholeMarsBlog  Trotter87528503   nt\n",
       "1        elonmusk  Space_Dog_Phill   nt\n",
       "2        elonmusk         mrstego1   nt\n",
       "3         EvaFoxU        1sammyson   nt\n",
       "4       ray4tesla     TONE13817103   nt\n",
       "..            ...              ...  ...\n",
       "56       elonmusk        otacon122   nt\n",
       "57      ray4tesla        ray4tesla    t\n",
       "58   GailAlfarATX        otacon122   nt\n",
       "59       elonmusk        Leonari13   nt\n",
       "60       elonmusk    thiseffinguy7   nt\n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0d1640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top2.to_csv('top_100.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2099fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
